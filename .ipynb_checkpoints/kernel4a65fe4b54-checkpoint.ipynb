{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>src_lat</th>\n",
       "      <th>src_lon</th>\n",
       "      <th>src_area</th>\n",
       "      <th>src_sub_area</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lon</th>\n",
       "      <th>dest_area</th>\n",
       "      <th>dest_sub_area</th>\n",
       "      <th>distance</th>\n",
       "      <th>status</th>\n",
       "      <th>confirmed_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59d005e1ffcfa261708ce9cd</td>\n",
       "      <td>59d005e9cb564761a8fe5d3e</td>\n",
       "      <td>59a892c5568be44b2734f276</td>\n",
       "      <td>59ad2d6efba75a581666b506</td>\n",
       "      <td>2017-10-01T00:00:17Z</td>\n",
       "      <td>41.070468</td>\n",
       "      <td>29.019451</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9s</td>\n",
       "      <td>41.117158</td>\n",
       "      <td>29.036495</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9u</td>\n",
       "      <td>5.379250</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59d0066affcfa261708ceb11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59cd704bcf482f6ce2fadfdb</td>\n",
       "      <td>2017-10-01T00:02:34Z</td>\n",
       "      <td>41.074868</td>\n",
       "      <td>28.995276</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>41.083514</td>\n",
       "      <td>29.002277</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>1.126098</td>\n",
       "      <td>nodrivers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59d006a1ffcfa261708ceba4</td>\n",
       "      <td>59d006c131e39c618969343d</td>\n",
       "      <td>599dc0dfa5b4fd5471ad8453</td>\n",
       "      <td>59bd62cc7e3c3b663924ba86</td>\n",
       "      <td>2017-10-01T00:03:29Z</td>\n",
       "      <td>41.049952</td>\n",
       "      <td>29.031073</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9s</td>\n",
       "      <td>41.044952</td>\n",
       "      <td>28.981922</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>4.169492</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59d006d8cb564761a8fe5efd</td>\n",
       "      <td>59d007193d32b861760d4a77</td>\n",
       "      <td>59a5856573d56e7103b5d51d</td>\n",
       "      <td>59c17cd1f6da2d274e16d0a7</td>\n",
       "      <td>2017-10-01T00:04:24Z</td>\n",
       "      <td>41.052873</td>\n",
       "      <td>28.995218</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>41.081403</td>\n",
       "      <td>28.981973</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>3.358296</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59d0073ecb564761a8fe5fdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>596f47a8a294a82ea3e90e77</td>\n",
       "      <td>2017-10-01T00:06:06Z</td>\n",
       "      <td>41.067595</td>\n",
       "      <td>28.988273</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9e</td>\n",
       "      <td>41.021249</td>\n",
       "      <td>29.113156</td>\n",
       "      <td>sxk9</td>\n",
       "      <td>sxk9q</td>\n",
       "      <td>11.693573</td>\n",
       "      <td>nodrivers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                   trip_id  \\\n",
       "0  59d005e1ffcfa261708ce9cd  59d005e9cb564761a8fe5d3e   \n",
       "1  59d0066affcfa261708ceb11                       NaN   \n",
       "2  59d006a1ffcfa261708ceba4  59d006c131e39c618969343d   \n",
       "3  59d006d8cb564761a8fe5efd  59d007193d32b861760d4a77   \n",
       "4  59d0073ecb564761a8fe5fdc                       NaN   \n",
       "\n",
       "                  driver_id                  rider_id            start_time  \\\n",
       "0  59a892c5568be44b2734f276  59ad2d6efba75a581666b506  2017-10-01T00:00:17Z   \n",
       "1                       NaN  59cd704bcf482f6ce2fadfdb  2017-10-01T00:02:34Z   \n",
       "2  599dc0dfa5b4fd5471ad8453  59bd62cc7e3c3b663924ba86  2017-10-01T00:03:29Z   \n",
       "3  59a5856573d56e7103b5d51d  59c17cd1f6da2d274e16d0a7  2017-10-01T00:04:24Z   \n",
       "4                       NaN  596f47a8a294a82ea3e90e77  2017-10-01T00:06:06Z   \n",
       "\n",
       "     src_lat    src_lon src_area src_sub_area   dest_lat   dest_lon dest_area  \\\n",
       "0  41.070468  29.019451     sxk9        sxk9s  41.117158  29.036495      sxk9   \n",
       "1  41.074868  28.995276     sxk9        sxk9e  41.083514  29.002277      sxk9   \n",
       "2  41.049952  29.031073     sxk9        sxk9s  41.044952  28.981922      sxk9   \n",
       "3  41.052873  28.995218     sxk9        sxk9e  41.081403  28.981973      sxk9   \n",
       "4  41.067595  28.988273     sxk9        sxk9e  41.021249  29.113156      sxk9   \n",
       "\n",
       "  dest_sub_area   distance     status  confirmed_time_sec  \n",
       "0         sxk9u   5.379250  confirmed                   8  \n",
       "1         sxk9e   1.126098  nodrivers                   0  \n",
       "2         sxk9e   4.169492  confirmed                  32  \n",
       "3         sxk9e   3.358296  confirmed                  65  \n",
       "4         sxk9q  11.693573  nodrivers                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scotty = pd.read_csv(\"data/data-train.csv\")\n",
    "scotty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90113 entries, 0 to 90112\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   start_time    90113 non-null  object\n",
      " 1   src_sub_area  90113 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "scotty = scotty[['start_time','src_sub_area']]\n",
    "#scotty.head()\n",
    "\n",
    "scotty.info()\n",
    "\n",
    "scotty.start_time = scotty.start_time.astype('datetime64[ns]')\n",
    "scotty.columns = ['datetime','src_sub_area']\n",
    "# print(scotty.head())\n",
    "# print(scotty.tail())\n",
    "\n",
    "scotty['datetime'] = scotty['datetime'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "# print(scotty.head())\n",
    "# print(scotty.tail())\n",
    "\n",
    "scotty_group = scotty.groupby(['datetime','src_sub_area']).count()\n",
    "scotty_group.reset_index(inplace=True)\n",
    "\n",
    "a = scotty.groupby(['datetime','src_sub_area'])['src_sub_area'].count()\n",
    "scotty_group['demand'] = a.reset_index(drop=True)\n",
    "# scotty_group.head()\n",
    "\n",
    "scotty_group.sort_values(by=['src_sub_area','datetime'], inplace=True)\n",
    "\n",
    "scotty_group = scotty_group.groupby('src_sub_area').\\\n",
    "    apply(lambda x : x.set_index('datetime').resample('H').sum().fillna(0)).\\\n",
    "    reset_index()\n",
    "\n",
    "sxk97 = scotty_group[scotty_group.src_sub_area == 'sxk97']\n",
    "sxk9e = scotty_group[scotty_group.src_sub_area == 'sxk9e']\n",
    "sxk9s = scotty_group[scotty_group.src_sub_area == 'sxk9s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['src_sub_area'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6c47cc470eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msxk97\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msxk97\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src_sub_area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msxk97\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m         )\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['src_sub_area'] not found in axis\""
     ]
    }
   ],
   "source": [
    "sxk97 = sxk97.drop(columns=['src_sub_area'])\n",
    "sxk97.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 01:00:00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 02:00:00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 03:00:00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     demand\n",
       "datetime                   \n",
       "2017-10-01 00:00:00       6\n",
       "2017-10-01 01:00:00       4\n",
       "2017-10-01 02:00:00       9\n",
       "2017-10-01 03:00:00       2\n",
       "2017-10-01 04:00:00       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sxk97\n",
    "# df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From MachineLearningMastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_data)\n",
    "scaled_train_data = scaler.transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate multi-step vector-output stacked lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "# raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "raw_seq = train_data['demand'].tolist()\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 24*7, 2\n",
    "# n_steps_in, n_steps_out = n_test*3, n_test\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# X = raw.reshape(raw.shape[1], raw.shape[0], n_features)\n",
    "# y = test_data.values\n",
    "# y = y.reshape(y.shape[1], y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losse = model.history.history['loss']\n",
    "plt.plot(range(len(losse)), losse)\n",
    "plt.show()\n",
    "# losse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[120.097084 138.88902 ]]\n",
    "[[116.9725  131.78836]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 24*7\n",
    "train_data = df[:len(df)-n_test]\n",
    "test_data = df[len(df)-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From MachineLearningMastery MultiStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1170/1170 [==============================] - 3s 2ms/step - loss: 237.1213\n",
      "Epoch 2/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 163.6437\n",
      "Epoch 3/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 154.1377\n",
      "Epoch 4/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 151.4798\n",
      "Epoch 5/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 155.0213\n",
      "Epoch 6/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 143.6017\n",
      "Epoch 7/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 145.5888\n",
      "Epoch 8/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 137.7965\n",
      "Epoch 9/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 137.1559\n",
      "Epoch 10/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 133.4056\n",
      "Epoch 11/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 137.5443\n",
      "Epoch 12/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 130.3538\n",
      "Epoch 13/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 141.2943A: 0s - loss: 146.7\n",
      "Epoch 14/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 130.4135\n",
      "Epoch 15/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 131.9127\n",
      "Epoch 16/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 132.1525\n",
      "Epoch 17/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 126.6441\n",
      "Epoch 18/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 126.0218A:\n",
      "Epoch 19/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 122.9524\n",
      "Epoch 20/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 124.0693\n",
      "Epoch 21/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 122.5529\n",
      "Epoch 22/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 120.0222\n",
      "Epoch 23/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 125.5513\n",
      "Epoch 24/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 120.5581\n",
      "Epoch 25/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 135.4752A: \n",
      "Epoch 26/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 119.6296\n",
      "Epoch 27/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 126.1768A: 0s - loss: 12\n",
      "Epoch 28/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 115.6267\n",
      "Epoch 29/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 115.0892\n",
      "Epoch 30/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 114.5063\n",
      "Epoch 31/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 113.2016\n",
      "Epoch 32/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 113.2159 0s - loss: 98. - ETA: 0s \n",
      "Epoch 33/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 110.4303\n",
      "Epoch 34/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 113.0371\n",
      "Epoch 35/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 108.8198\n",
      "Epoch 36/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 105.4913\n",
      "Epoch 37/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 109.2616\n",
      "Epoch 38/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 103.7139\n",
      "Epoch 39/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 99.8193\n",
      "Epoch 40/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 101.6295A: 0s - loss: 101.81\n",
      "Epoch 41/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 96.2609\n",
      "Epoch 42/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 97.2609\n",
      "Epoch 43/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 102.3315\n",
      "Epoch 44/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 94.4107\n",
      "Epoch 45/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 90.0643\n",
      "Epoch 46/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 100.0123\n",
      "Epoch 47/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 89.5274\n",
      "Epoch 48/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 86.9929\n",
      "Epoch 49/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 83.9455\n",
      "Epoch 50/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 78.4648\n",
      "Epoch 51/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 83.8822\n",
      "Epoch 52/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 75.4466: 0s - loss: 7\n",
      "Epoch 53/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 71.9629\n",
      "Epoch 54/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 77.3624\n",
      "Epoch 55/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 89.2082\n",
      "Epoch 56/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 74.3551\n",
      "Epoch 57/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 70.8203\n",
      "Epoch 58/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 68.1752\n",
      "Epoch 59/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 69.4192\n",
      "Epoch 60/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 61.7582\n",
      "Epoch 61/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 60.0865\n",
      "Epoch 62/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 58.3372\n",
      "Epoch 63/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 54.3417\n",
      "Epoch 64/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 52.9751\n",
      "Epoch 65/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 59.9496\n",
      "Epoch 66/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 51.9505: 0s -\n",
      "Epoch 67/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 51.2553\n",
      "Epoch 68/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 46.7352\n",
      "Epoch 69/70\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 44.8635\n",
      "Epoch 70/70\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 48.1290\n",
      "lstm: [18.658] 7.0, 15.6, 16.2, 21.6, 25.2, 20.5, 19.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# univariate multi-step lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "\t# split into standard weeks\n",
    "\ttrain, test = data[1:-328], data[-328:-6]\n",
    "\t# restructure into windows of weekly data\n",
    "\ttrain = array(split(train, len(train)/7))\n",
    "\ttest = array(split(test, len(test)/7))\n",
    "\treturn train, test\n",
    " \n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    " \n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    " \n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "\t# flatten data\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor _ in range(len(data)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tin_end = in_start + n_input\n",
    "\t\tout_end = in_end + n_out\n",
    "\t\t# ensure we have enough data for this instance\n",
    "\t\tif out_end <= len(data):\n",
    "\t\t\tx_input = data[in_start:in_end, 0]\n",
    "\t\t\tx_input = x_input.reshape((len(x_input), 1))\n",
    "\t\t\tX.append(x_input)\n",
    "\t\t\ty.append(data[in_end:out_end, 0])\n",
    "\t\t# move along one time step\n",
    "\t\tin_start += 1\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "\t# prepare data\n",
    "\ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\t# define parameters\n",
    "\tverbose, epochs, batch_size = 1, 70, 16\n",
    "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit network\n",
    "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model\n",
    " \n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, 0]\n",
    "\t# reshape into [1, n_input, 1]\n",
    "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores\n",
    " \n",
    "# load the new file\n",
    "# dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "dataset = df\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# evaluate model and get scores\n",
    "n_input = 7\n",
    "score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sunday', 'Sunday', 'Sunday', 'Sunday', 'Sunday', 'Sunday', 'Sunday',\n",
      "       'Sunday', 'Sunday', 'Sunday',\n",
      "       ...\n",
      "       'Saturday', 'Saturday', 'Saturday', 'Saturday', 'Saturday', 'Saturday',\n",
      "       'Saturday', 'Saturday', 'Saturday', 'Saturday'],\n",
      "      dtype='object', name='datetime', length=1512)\n"
     ]
    }
   ],
   "source": [
    "print(df.index.day_name())\n",
    "# print(df.index[2].dayofweek)\n",
    "\n",
    "# print(df.index[-1].day_name())\n",
    "# print(df.index[-1].dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From TowardsDataScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[:len(df)-252]\n",
    "test_data = df[len(df)-252:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_data)\n",
    "scaled_train_data = scaler.transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 1000\n",
    "n_features= 1\n",
    "generator = TimeseriesGenerator(scaled_train_data, scaled_train_data, length=n_input, batch_size=252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(10, activation='tanh', input_shape=(n_input, n_features)))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.fit_generator(generator,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_lstm = lstm_model.history.history['loss']\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.plot(range(len(losses_lstm)),losses_lstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions_scaled = list()\n",
    "\n",
    "batch = scaled_train_data[-n_input:]\n",
    "current_batch = batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test_data)):   \n",
    "    lstm_pred = lstm_model.predict(current_batch)[0]\n",
    "    lstm_predictions_scaled.append(lstm_pred) \n",
    "    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = lstm_model.predict(scaled_train_data.reshape(1, 1260, n_features))\n",
    "# aa = scaler.inverse_transform(aa)\n",
    "# plt.plot(train_data.index, aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['LSTM pred'] = lstm_predictions\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_data.index, test_data['demand'])\n",
    "plt.plot(test_data.index, test_data['LSTM pred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on TF web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i+target_size])\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data = sxk97.values\n",
    "TRAIN_SPLIT = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
    "uni_train_std = uni_data[:TRAIN_SPLIT].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data = (uni_data-uni_train_mean)/uni_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_past_history = 20\n",
    "univariate_future_target = 0\n",
    "\n",
    "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                           univariate_past_history,\n",
    "                                           univariate_future_target)\n",
    "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                       univariate_past_history,\n",
    "                                       univariate_future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 100\n",
    "\n",
    "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate, validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(3):\n",
    "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "  plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_TF = simple_lstm_model.history.history['loss']\n",
    "plt.plot(range(len(losses_TF)), losses_TF)\n",
    "\n",
    "# losses_lstm = lstm_model.history.history['loss']\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.xticks(np.arange(0,21,1))\n",
    "# plt.plot(range(len(losses_lstm)),losses_lstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "#                     simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "# plot.show()\n",
    "\n",
    "pred = simple_lstm_model.predict(x_val_uni)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
